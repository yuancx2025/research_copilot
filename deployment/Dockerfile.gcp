# GCP-optimized Dockerfile (uses Google Gemini API, no Ollama)
FROM python:3.11-slim

ENV PYTHONUNBUFFERED=1
ENV GRADIO_SERVER_NAME=0.0.0.0
ENV GRADIO_SERVER_PORT=7860

# Install system dependencies
RUN apt-get update && apt-get install -y \
    curl \
    ca-certificates \
    && rm -rf /var/lib/apt/lists/*

# Create non-root user
RUN useradd -m -u 1000 user

# Set working directory
WORKDIR /app

# Copy requirements and install Python dependencies as root (installs to system locations)
COPY requirements.txt .
RUN pip install --no-cache-dir --upgrade pip && \
    pip install --no-cache-dir --upgrade -r requirements.txt

# Pre-download sentence-transformers model with Hugging Face token to avoid rate limiting
# HF_TOKEN is passed as build arg from Cloud Build
ARG HF_TOKEN
RUN if [ -n "$HF_TOKEN" ]; then \
        export HF_TOKEN=$HF_TOKEN && \
        echo "Pre-downloading model with HF token..." && \
        python -c "import os; os.environ['HF_TOKEN'] = '$HF_TOKEN'; from sentence_transformers import SentenceTransformer; SentenceTransformer('sentence-transformers/all-mpnet-base-v2')" && \
        echo "✓ Model pre-downloaded successfully"; \
    else \
        echo "⚠ Warning: HF_TOKEN not provided, model will download at runtime (may hit rate limits)"; \
    fi

# Set Hugging Face cache location (persists across container restarts if using persistent volume)
ENV HF_HOME=/tmp/.cache/huggingface

# Copy application code and set ownership
COPY . .
RUN chown -R user:user /app

# Switch to non-root user
USER user
ENV PATH="/usr/local/bin:/home/user/.local/bin:$PATH"

# Expose port
EXPOSE 7860

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=40s --retries=3 \
    CMD curl -f http://localhost:7860/ || exit 1

# Run the application
CMD ["python", "app.py"]
